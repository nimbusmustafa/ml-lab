{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (C4.5): {'Temp.': {85: 'No', 80: 'No', 83: 'Yes', 70: 'Yes', 68: 'Yes', 65: 'No', 64: 'Yes', 72: {'Outlook': {'Sunny': 'No', 'Overcast': 'Yes'}}, 69: 'Yes', 75: 'Yes', 81: 'Yes', 71: 'No'}}\n",
      "Classification of new sample (C4.5): No\n",
      "\n",
      "Decision Tree (CART): {'Temp.': {85: 'No', 80: 'No', 83: 'Yes', 70: 'Yes', 68: 'Yes', 65: 'No', 64: 'Yes', 72: {'Outlook': {'Sunny': 'No', 'Overcast': 'Yes'}}, 69: 'Yes', 75: 'Yes', 81: 'Yes', 71: 'No'}}\n",
      "Classification of new sample (CART): No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Sample dataset based on provided data\n",
    "data = [\n",
    "    {\"Outlook\": \"Sunny\", \"Temp.\": 85, \"Humidity\": 85, \"Wind\": \"Weak\", \"Decision\": \"No\"},\n",
    "    {\"Outlook\": \"Sunny\", \"Temp.\": 80, \"Humidity\": 90, \"Wind\": \"Strong\", \"Decision\": \"No\"},\n",
    "    {\"Outlook\": \"Overcast\", \"Temp.\": 83, \"Humidity\": 78, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Rain\", \"Temp.\": 70, \"Humidity\": 96, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Rain\", \"Temp.\": 68, \"Humidity\": 80, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Rain\", \"Temp.\": 65, \"Humidity\": 70, \"Wind\": \"Strong\", \"Decision\": \"No\"},\n",
    "    {\"Outlook\": \"Overcast\", \"Temp.\": 64, \"Humidity\": 65, \"Wind\": \"Strong\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Sunny\", \"Temp.\": 72, \"Humidity\": 95, \"Wind\": \"Weak\", \"Decision\": \"No\"},\n",
    "    {\"Outlook\": \"Sunny\", \"Temp.\": 69, \"Humidity\": 70, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Rain\", \"Temp.\": 75, \"Humidity\": 80, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Sunny\", \"Temp.\": 75, \"Humidity\": 70, \"Wind\": \"Strong\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Overcast\", \"Temp.\": 72, \"Humidity\": 90, \"Wind\": \"Strong\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Overcast\", \"Temp.\": 81, \"Humidity\": 75, \"Wind\": \"Weak\", \"Decision\": \"Yes\"},\n",
    "    {\"Outlook\": \"Rain\", \"Temp.\": 71, \"Humidity\": 80, \"Wind\": \"Strong\", \"Decision\": \"No\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate frequency of labels\n",
    "def label_frequency(data):\n",
    "    label_counts = {}\n",
    "    for label in data[\"Decision\"]:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    return label_counts\n",
    "\n",
    "# Function to calculate entropy (for C4.5)\n",
    "def entropy(data):\n",
    "    label_counts = label_frequency(data)\n",
    "    total_instances = len(data)\n",
    "    entropy_value = 0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total_instances\n",
    "        entropy_value -= probability * math.log2(probability)\n",
    "    return entropy_value\n",
    "\n",
    "# Function to calculate Gini impurity (for CART)\n",
    "def gini_impurity(data):\n",
    "    label_counts = label_frequency(data)\n",
    "    total_instances = len(data)\n",
    "    gini = 1\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total_instances\n",
    "        gini -= probability ** 2\n",
    "    return gini\n",
    "\n",
    "# Function to calculate information gain for C4.5\n",
    "def information_gain(data, attribute):\n",
    "    total_entropy = entropy(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_entropy = 0\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_entropy = entropy(subset)\n",
    "        weighted_entropy += (len(subset) / len(data)) * subset_entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Function to calculate Gini gain for CART\n",
    "def gini_gain(data, attribute):\n",
    "    total_gini = gini_impurity(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_gini = 0\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_gini = gini_impurity(subset)\n",
    "        weighted_gini += (len(subset) / len(data)) * subset_gini\n",
    "    return total_gini - weighted_gini\n",
    "\n",
    "# Function to find the best attribute to split on based on selected criterion\n",
    "def best_split(data, attributes, criterion=\"C4.5\"):\n",
    "    best_gain = -1\n",
    "    best_attribute = None\n",
    "    for attribute in attributes:\n",
    "        if criterion == \"C4.5\":\n",
    "            gain = information_gain(data, attribute)\n",
    "        elif criterion == \"CART\":\n",
    "            gain = gini_gain(data, attribute)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion specified. Choose 'C4.5' or 'CART'.\")\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute\n",
    "    return best_attribute\n",
    "\n",
    "# Recursive function to build the decision tree\n",
    "def build_tree(data, attributes, criterion=\"C4.5\"):\n",
    "    # If all target labels are the same, return that label\n",
    "    if len(data[\"Decision\"].unique()) == 1:\n",
    "        return data[\"Decision\"].iloc[0]\n",
    "    \n",
    "    # If there are no more attributes to split, return the most common label\n",
    "    if len(attributes) == 0:\n",
    "        return data[\"Decision\"].mode()[0]\n",
    "    \n",
    "    # Find the best attribute to split on\n",
    "    best_attr = best_split(data, attributes, criterion)\n",
    "    tree = {best_attr: {}}\n",
    "    remaining_attributes = [attr for attr in attributes if attr != best_attr]\n",
    "    \n",
    "    # Split on each possible value of the best attribute\n",
    "    for value in data[best_attr].unique():\n",
    "        subset = data[data[best_attr] == value]\n",
    "        subtree = build_tree(subset, remaining_attributes, criterion)\n",
    "        tree[best_attr][value] = subtree\n",
    "    return tree\n",
    "\n",
    "# Function to classify a new sample\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attribute = next(iter(tree))\n",
    "    value = sample.get(attribute)\n",
    "    if value not in tree[attribute]:\n",
    "        return \"Unknown\"\n",
    "    subtree = tree[attribute][value]\n",
    "    return classify(subtree, sample)\n",
    "\n",
    "# Building the decision trees using both C4.5 and CART\n",
    "attributes = [\"Outlook\", \"Temp.\", \"Humidity\", \"Wind\"]\n",
    "decision_tree_c4_5 = build_tree(df, attributes, criterion=\"C4.5\")\n",
    "decision_tree_cart = build_tree(df, attributes, criterion=\"CART\")\n",
    "\n",
    "# Sample for testing the classification\n",
    "new_sample = {\"Outlook\": \"Sunny\", \"Temp.\": 72, \"Humidity\": 90, \"Wind\": \"Weak\"}\n",
    "classification_c4_5 = classify(decision_tree_c4_5, new_sample)\n",
    "classification_cart = classify(decision_tree_cart, new_sample)\n",
    "\n",
    "# Display the results\n",
    "print(\"Decision Tree (C4.5):\", decision_tree_c4_5)\n",
    "print(\"Classification of new sample (C4.5):\", classification_c4_5)\n",
    "print(\"\\nDecision Tree (CART):\", decision_tree_cart)\n",
    "print(\"Classification of new sample (CART):\", classification_cart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (C4.5): {'Credit': {'Good': 'Yes', 'Bad': {'Income': {'Low': 'No', 'Medium': 'Yes', 'High': 'No'}}}}\n",
      "Classification of new sample (C4.5): Yes\n",
      "\n",
      "Decision Tree (CART): {'Credit': {'Good': 'Yes', 'Bad': {'Income': {'Low': 'No', 'Medium': 'Yes', 'High': 'No'}}}}\n",
      "Classification of new sample (CART): Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Sample dataset based on provided data\n",
    "data = [\n",
    "    {\"Income\": \"Low\", \"Credit\": \"Good\", \"Loan Approved\": \"Yes\"},\n",
    "    {\"Income\": \"Low\", \"Credit\": \"Bad\", \"Loan Approved\": \"No\"},\n",
    "    {\"Income\": \"Medium\", \"Credit\": \"Good\", \"Loan Approved\": \"Yes\"},\n",
    "    {\"Income\": \"Medium\", \"Credit\": \"Bad\", \"Loan Approved\": \"Yes\"},\n",
    "    {\"Income\": \"High\", \"Credit\": \"Good\", \"Loan Approved\": \"Yes\"},\n",
    "    {\"Income\": \"High\", \"Credit\": \"Bad\", \"Loan Approved\": \"No\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate frequency of labels\n",
    "def label_frequency(data):\n",
    "    label_counts = {}\n",
    "    for label in data[\"Loan Approved\"]:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    return label_counts\n",
    "\n",
    "# Function to calculate entropy (for C4.5)\n",
    "def entropy(data):\n",
    "    label_counts = label_frequency(data)\n",
    "    total_instances = len(data)\n",
    "    entropy_value = 0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total_instances\n",
    "        entropy_value -= probability * math.log2(probability)\n",
    "    return entropy_value\n",
    "\n",
    "# Function to calculate Gini impurity (for CART)\n",
    "def gini_impurity(data):\n",
    "    label_counts = label_frequency(data)\n",
    "    total_instances = len(data)\n",
    "    gini = 1\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total_instances\n",
    "        gini -= probability ** 2\n",
    "    return gini\n",
    "\n",
    "# Function to calculate information gain for C4.5\n",
    "def information_gain(data, attribute):\n",
    "    total_entropy = entropy(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_entropy = 0\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_entropy = entropy(subset)\n",
    "        weighted_entropy += (len(subset) / len(data)) * subset_entropy\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Function to calculate Gini gain for CART\n",
    "def gini_gain(data, attribute):\n",
    "    total_gini = gini_impurity(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_gini = 0\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_gini = gini_impurity(subset)\n",
    "        weighted_gini += (len(subset) / len(data)) * subset_gini\n",
    "    return total_gini - weighted_gini\n",
    "\n",
    "# Function to find the best attribute to split on based on selected criterion\n",
    "def best_split(data, attributes, criterion=\"C4.5\"):\n",
    "    best_gain = -1\n",
    "    best_attribute = None\n",
    "    for attribute in attributes:\n",
    "        if criterion == \"C4.5\":\n",
    "            gain = information_gain(data, attribute)\n",
    "        elif criterion == \"CART\":\n",
    "            gain = gini_gain(data, attribute)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion specified. Choose 'C4.5' or 'CART'.\")\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute\n",
    "    return best_attribute\n",
    "\n",
    "# Recursive function to build the decision tree\n",
    "def build_tree(data, attributes, criterion=\"C4.5\"):\n",
    "    # If all target labels are the same, return that label\n",
    "    if len(data[\"Loan Approved\"].unique()) == 1:\n",
    "        return data[\"Loan Approved\"].iloc[0]\n",
    "    \n",
    "    # If there are no more attributes to split, return the most common label\n",
    "    if len(attributes) == 0:\n",
    "        return data[\"Loan Approved\"].mode()[0]\n",
    "    \n",
    "    # Find the best attribute to split on\n",
    "    best_attr = best_split(data, attributes, criterion)\n",
    "    tree = {best_attr: {}}\n",
    "    remaining_attributes = [attr for attr in attributes if attr != best_attr]\n",
    "    \n",
    "    # Split on each possible value of the best attribute\n",
    "    for value in data[best_attr].unique():\n",
    "        subset = data[data[best_attr] == value]\n",
    "        subtree = build_tree(subset, remaining_attributes, criterion)\n",
    "        tree[best_attr][value] = subtree\n",
    "    return tree\n",
    "\n",
    "# Function to classify a new sample\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attribute = next(iter(tree))\n",
    "    value = sample.get(attribute)\n",
    "    if value not in tree[attribute]:\n",
    "        return \"Unknown\"\n",
    "    subtree = tree[attribute][value]\n",
    "    return classify(subtree, sample)\n",
    "\n",
    "# Building the decision trees using both C4.5 and CART\n",
    "attributes = [\"Income\", \"Credit\"]\n",
    "decision_tree_c4_5 = build_tree(df, attributes, criterion=\"C4.5\")\n",
    "decision_tree_cart = build_tree(df, attributes, criterion=\"CART\")\n",
    "\n",
    "# Sample for testing the classification\n",
    "new_sample = {\"Income\": \"Medium\", \"Credit\": \"Good\"}\n",
    "classification_c4_5 = classify(decision_tree_c4_5, new_sample)\n",
    "classification_cart = classify(decision_tree_cart, new_sample)\n",
    "\n",
    "# Display the results\n",
    "print(\"Decision Tree (C4.5):\", decision_tree_c4_5)\n",
    "print(\"Classification of new sample (C4.5):\", classification_c4_5)\n",
    "print(\"\\nDecision Tree (CART):\", decision_tree_cart)\n",
    "print(\"Classification of new sample (CART):\", classification_cart)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
